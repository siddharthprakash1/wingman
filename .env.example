# Wingman AI Assistant - Environment Configuration
# Copy this file to .env and fill in your actual API keys
# 
# Quick Start:
# 1. Get a free Kimi API key at: https://platform.moonshot.cn
# 2. Copy this file: cp .env.example .env
# 3. Add your KIMI_API_KEY to .env
# 4. Run: python -m src.cli.app onboard

# =============================================================================
# WORKSPACE CONFIGURATION (Security & Sandboxing)
# =============================================================================

# Workspace directory for all agent operations (files, shell commands)
# Default: ~/.wingman/workspace
# Set to a dedicated directory to enable secure sandboxing
WINGMAN_WORKSPACE=~/.wingman/workspace

# Enable workspace sandboxing (highly recommended for security)
# When enabled, all file and shell operations are restricted to WINGMAN_WORKSPACE
# Default: true
WINGMAN_WORKSPACE_SANDBOXED=true

# =============================================================================
# LLM PROVIDERS (At least one required)
# =============================================================================

# -----------------------------------------------------------------------------
# KIMI (Moonshot K2.5) - DEFAULT PROVIDER - FREE TIER AVAILABLE ‚≠ê
# -----------------------------------------------------------------------------
# Get your free API key at: https://platform.moonshot.cn
# This is the default and recommended provider for Wingman
KIMI_API_KEY=your_kimi_api_key_here
# KIMI_API_BASE=https://api.moonshot.cn/v1  # Optional: custom endpoint

# -----------------------------------------------------------------------------
# GOOGLE GEMINI / VERTEX AI (Primary Alternative - Free Tier Available)
# -----------------------------------------------------------------------------

# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_API_BASE=https://generativelanguage.googleapis.com/v1beta  # Optional

# For LangExtract compatibility:
GOOGLE_API_KEY=your_google_api_key_here
LANGEXTRACT_API_KEY=your_google_api_key_here

# -----------------------------------------------------------------------------
# OPENAI (GPT-4, GPT-4o)
# -----------------------------------------------------------------------------
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_API_BASE=https://api.openai.com/v1  # Optional: custom endpoint

# -----------------------------------------------------------------------------
# OPENROUTER (Multi-Model Proxy)
# -----------------------------------------------------------------------------
# Get your key from: https://openrouter.ai
# Access Claude, Llama, Mistral, and many other models
OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENROUTER_API_BASE=https://openrouter.ai/api/v1  # Optional

# -----------------------------------------------------------------------------
# ANTHROPIC / CLAUDE (Optional)
# -----------------------------------------------------------------------------
# Get your key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# -----------------------------------------------------------------------------
# OLLAMA (Local Models - No API Key Required)
# -----------------------------------------------------------------------------
# No API key needed for local Ollama models
# Just ensure Ollama is running: ollama serve
# Default URL: http://localhost:11434
OLLAMA_API_BASE=http://localhost:11434

# =============================================================================
# MESSAGING CHANNELS (Optional - For Multi-Channel Access)
# =============================================================================

# -----------------------------------------------------------------------------
# TELEGRAM
# -----------------------------------------------------------------------------
# Create a bot with @BotFather on Telegram
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# -----------------------------------------------------------------------------
# DISCORD
# -----------------------------------------------------------------------------
# Create an application at: https://discord.com/developers/applications
DISCORD_BOT_TOKEN=your_discord_bot_token_here

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Default LLM Model (format: provider/model-name)
# Options:
#   - kimi/kimi-k2.5              (Moonshot K2.5 - default)
#   - gemini/gemini-2.5-flash     (Fast, cost-effective)
#   - gemini/gemini-2.5-pro       (Best reasoning)
#   - ollama/deepseek-r1:14b      (Local reasoning model)
#   - ollama/llama3:latest        (Local general purpose)
#   - openai/gpt-4o               (OpenAI latest)
#   - openai/gpt-4o-mini          (OpenAI cost-effective)
#   - openrouter/anthropic/claude-opus-4-5  (Claude via OpenRouter)
DEFAULT_MODEL=kimi/kimi-k2.5

# Workspace Directory (where sessions, memory, and logs are stored)
WORKSPACE_PATH=~/.wingman/workspace

# Gateway Server Configuration
GATEWAY_HOST=127.0.0.1
GATEWAY_PORT=18789

# Logging Level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Maximum tokens for LLM responses
MAX_TOKENS=4000

# Temperature for LLM (0.0 - 1.0, higher = more creative)
TEMPERATURE=0.7

# Maximum tool execution iterations per request
MAX_TOOL_ITERATIONS=25

# Session timeout in seconds (default: 1 hour)
SESSION_TIMEOUT=3600

# =============================================================================
# TOOLS CONFIGURATION (Optional)
# =============================================================================

# Web Search - DuckDuckGo (No API key needed by default)
# For enhanced search capabilities:
# SERPAPI_KEY=your_serpapi_key_here
# BRAVE_SEARCH_API_KEY=your_brave_search_key_here

# Embeddings Model for Semantic Search (Local, no API key needed)
# Options: all-MiniLM-L6-v2 (fast), all-mpnet-base-v2 (better quality)
EMBEDDINGS_MODEL=all-MiniLM-L6-v2

# =============================================================================
# SECURITY SETTINGS
# =============================================================================

# Enable/Disable shell command execution (true/false)
ALLOW_SHELL_COMMANDS=true

# Enable/Disable file system access (true/false)
ALLOW_FILESYSTEM_ACCESS=true

# Allowed workspace directories (comma-separated absolute paths)
# ALLOWED_WORKSPACES=/home/user/projects,/home/user/documents

# =============================================================================
# EXAMPLE USAGE PATTERNS
# =============================================================================

# CLI Mode:
#   python -m src.cli.app agent -m \"Research quantum computing\"
#
# Gateway Mode:
#   python -m src.cli.app gateway --port 18789
#
# Configure Channels:
#   python -m src.cli.app channels login --telegram
#
# System Doctor:
#   python -m src.cli.app doctor

# =============================================================================
# SECURITY NOTES
# =============================================================================

# 1. NEVER commit .env files with real API keys to version control
# 2. Add .env to your .gitignore file
# 3. Use environment variables in production, not hardcoded keys
# 4. Rotate API keys regularly
# 5. Use separate keys for development and production
# 6. Monitor API usage to detect unexpected costs

# =============================================================================
# ADDITIONAL CONFIGURATION (Optional)
# =============================================================================

# Optional: Set default model
# LANGEXTRACT_DEFAULT_MODEL=gemini-2.5-flash

# Optional: Set request timeout (in seconds)
# LANGEXTRACT_TIMEOUT=60

# Optional: Enable debug logging
# LANGEXTRACT_DEBUG=true
