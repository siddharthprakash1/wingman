# LangExtract API Configuration
# Copy this file to .env and fill in your actual API keys

# =============================================================================
# GOOGLE GEMINI / VERTEX AI (Primary Recommended Provider)
# =============================================================================

# Option 1: Google AI Studio API Key (for Gemini models)
# Get your key from: https://aistudio.google.com/app/apikey
LANGEXTRACT_API_KEY=your-google-ai-studio-api-key-here

# Alternative variable name (also accepted)
GOOGLE_API_KEY=your-google-api-key-here

# Option 2: Vertex AI (for enterprise/GCP users)
# Uses service account authentication instead of API key
# Set language_model_params in code:
#   language_model_params={
#       "vertexai": True,
#       "project": "your-gcp-project-id",
#       "location": "global"  # or "us-central1", etc.
#   }

# =============================================================================
# OPENAI (Optional - requires pip install langextract[openai])
# =============================================================================

# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Note: When using OpenAI models, you must set:
#   fence_output=True
#   use_schema_constraints=False
# in your lx.extract() call

# =============================================================================
# ANTHROPIC / CLAUDE (Optional - community provider)
# =============================================================================

# Get your key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# =============================================================================
# OLLAMA (Local Models - No API Key Required)
# =============================================================================

# No API key needed for local Ollama models
# Just ensure Ollama is running: ollama serve
# Default URL: http://localhost:11434

# Optional: Custom Ollama URL if not running on default port
# OLLAMA_HOST=http://localhost:11434

# =============================================================================
# MODEL SELECTION GUIDE
# =============================================================================

# Recommended models by use case:
#
# DEFAULT (Best balance):
#   model_id="gemini-2.5-flash"
#
# COMPLEX REASONING:
#   model_id="gemini-2.5-pro"
#
# COST-EFFECTIVE:
#   model_id="gemini-2.5-flash"
#
# OPENAI ALTERNATIVE:
#   model_id="gpt-4o"
#   model_id="gpt-4o-mini"
#
# LOCAL/PRIVATE:
#   model_id="gemma2:2b"  # via Ollama
#   model_id="llama3.1:8b"  # via Ollama

# =============================================================================
# EXAMPLE USAGE
# =============================================================================

# import langextract as lx
#
# # Using environment variables (recommended)
# result = lx.extract(
#     text_or_documents="Your text here",
#     prompt_description="Extract entities...",
#     examples=[...],
#     model_id="gemini-2.5-flash"
# )
#
# # Using OpenAI (requires additional parameters)
# result = lx.extract(
#     text_or_documents="Your text here",
#     prompt_description="Extract entities...",
#     examples=[...],
#     model_id="gpt-4o",
#     api_key=os.environ.get('OPENAI_API_KEY'),
#     fence_output=True,
#     use_schema_constraints=False
# )
#
# # Using Ollama (local, no API key)
# result = lx.extract(
#     text_or_documents="Your text here",
#     prompt_description="Extract entities...",
#     examples=[...],
#     model_id="gemma2:2b",
#     model_url="http://localhost:11434",
#     fence_output=False,
#     use_schema_constraints=False
# )

# =============================================================================
# SECURITY NOTES
# =============================================================================

# 1. NEVER commit .env files with real API keys to version control
# 2. Add .env to your .gitignore file
# 3. Use environment variables in production, not hardcoded keys
# 4. Rotate API keys regularly
# 5. Use separate keys for development and production
# 6. Monitor API usage to detect unexpected costs

# =============================================================================
# ADDITIONAL CONFIGURATION (Optional)
# =============================================================================

# Optional: Set default model
# LANGEXTRACT_DEFAULT_MODEL=gemini-2.5-flash

# Optional: Set request timeout (in seconds)
# LANGEXTRACT_TIMEOUT=60

# Optional: Enable debug logging
# LANGEXTRACT_DEBUG=true
